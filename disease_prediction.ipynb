{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udd3d Auto-download dataset from Kaggle (requires Kaggle API credentials in ~/.kaggle/kaggle.json)\n", "import os, glob\n", "try:\n", "    import opendatasets as od\n", "    od.download('https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset', data_dir='data')\n", "    # Find heart.csv wherever Kaggle placed it\n", "    candidates = glob.glob('data/**/heart.csv', recursive=True)\n", "    if candidates:\n", "        target_path = 'data/heart.csv'\n", "        if candidates[0] != target_path:\n", "            os.makedirs('data', exist_ok=True)\n", "            import shutil\n", "            shutil.copyfile(candidates[0], target_path)\n", "        print('\u2705 heart.csv ready at data/heart.csv')\n", "    else:\n", "        print('\u26a0\ufe0f heart.csv not found after download. You may need to accept terms on Kaggle.')\n", "except Exception as e:\n", "    print('\u26a0\ufe0f Kaggle download failed:', e)\n", "    print('Please place heart.csv into the data/ folder manually.')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udfe5 AI Disease Diagnosis System - Heart Disease Prediction\n", "\n", "**Author**: Imani Gad  \n", "**Date**: 2024  \n", "**Objective**: Build an explainable ML model to predict heart disease from patient clinical data\n", "\n", "---\n", "\n", "## Table of Contents\n", "1. Setup & Imports\n", "2. Auto-Download Dataset (Kaggle)\n", "3. Data Loading\n", "4. Exploratory Data Analysis (EDA)\n", "5. Data Preprocessing\n", "6. Model Training\n", "7. Model Evaluation\n", "8. SHAP Explainability\n", "9. Testing on New Patient\n", "10. Model Saving\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Setup & Imports"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "# Visualization\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "# Machine Learning\n", "from sklearn.model_selection import train_test_split, cross_val_score\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_fscore_support\n", "\n", "# Explainable AI\n", "import shap\n", "\n", "# Persistence\n", "import joblib, os\n", "\n", "RANDOM_STATE = 42\n", "np.random.seed(RANDOM_STATE)\n", "\n", "print(\"\u2705 Libraries ready\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Data Loading"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import os\n", "import pandas as pd\n", "\n", "df = pd.read_csv('data/heart.csv')\n", "print(\"\ud83d\udcca Dataset loaded:\", df.shape)\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Exploratory Data Analysis (EDA)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["df.info()\n", "df.describe()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Target distribution\n", "ax = sns.countplot(x='target', data=df)\n", "ax.set_title('Target Distribution (0=no disease, 1=disease)')\n", "plt.show()\n", "\n", "# Correlation heatmap\n", "plt.figure(figsize=(10,8))\n", "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n", "plt.title('Correlation Heatmap')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Data Preprocessing"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["X = df.drop('target', axis=1)\n", "y = df['target']\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n", "\n", "scaler = StandardScaler()\n", "X_train_scaled = scaler.fit_transform(X_train)\n", "X_test_scaled = scaler.transform(X_test)\n", "\n", "print(X_train.shape, X_test.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Model Training"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, solver='lbfgs')\n", "model.fit(X_train_scaled, y_train)\n", "\n", "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n", "print(\"CV mean accuracy:\", cv_scores.mean())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Model Evaluation"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["y_pred = model.predict(X_test_scaled)\n", "y_pred_proba = model.predict_proba(X_test_scaled)[:,1]\n", "\n", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "print(classification_report(y_test, y_pred, target_names=['No Disease','Heart Disease']))\n", "\n", "cm = confusion_matrix(y_test, y_pred)\n", "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n", "            xticklabels=['No Disease','Heart Disease'],\n", "            yticklabels=['No Disease','Heart Disease'])\n", "plt.title('Confusion Matrix'); plt.ylabel('Actual'); plt.xlabel('Predicted'); plt.show()\n", "\n", "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n", "auc = roc_auc_score(y_test, y_pred_proba)\n", "plt.plot(fpr, tpr, label=f'AUC={auc:.2f}'); plt.plot([0,1],[0,1],'--')\n", "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve'); plt.legend(); plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. SHAP Explainability"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["explainer = shap.LinearExplainer(model, X_train_scaled)\n", "shap_values = explainer.shap_values(X_test_scaled)\n", "\n", "# Global importance (bar)\n", "shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns, plot_type='bar')"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Detailed summary\n", "shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. Testing on New Patient"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["new_patient = pd.DataFrame({\n", "    'age':[58],'sex':[1],'cp':[2],'trestbps':[150],'chol':[280],'fbs':[1],'restecg':[1],\n", "    'thalach':[140],'exang':[1],'oldpeak':[2.5],'slope':[2],'ca':[2],'thal':[3]\n", "})\n", "new_scaled = scaler.transform(new_patient)\n", "pred = model.predict(new_scaled)[0]\n", "proba = model.predict_proba(new_scaled)[0]\n", "pred, proba"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# SHAP explanation for new patient\n", "new_shap = explainer.shap_values(new_scaled)\n", "contrib = pd.DataFrame({'Feature': X.columns, 'Value': new_patient.iloc[0].values, 'SHAP Value': new_shap[0]}).sort_values('SHAP Value', key=abs, ascending=False)\n", "contrib.head(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 10. Model Saving"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["os.makedirs('models', exist_ok=True)\n", "joblib.dump(model, 'models/logistic_model.pkl')\n", "joblib.dump(scaler, 'models/scaler.pkl')\n", "joblib.dump(list(X.columns), 'models/feature_names.pkl')\n", "print('\u2705 Saved model, scaler, and feature names.')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8.0"}}, "nbformat": 4, "nbformat_minor": 4}